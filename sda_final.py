# -*- coding: utf-8 -*-
"""SDA_FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wfnSmDHUbkjlflzkDjuG3I24iblkgQPQ

This code forms the basis for the SDA (Semi-Deterministic Algorithm) described in my paper. It can generate a turbulant signal for 1D that is spectrally accurate and matches the intermittancy of the sample seed.

The general approach is this:
1. Calculate a set of possible next values (a few hunderad is sufficent)
2. For each one calulate its loss function. This is a measure of how well it maintains the statistical properties, such as intermittancy and spectrum.
3. Assign a probability to each result based on the loss function, to introduce randomness but also keep the loss low.
4. Randomly select from the possble next values and apend this to the signal.
5. Repeat
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy.special import gamma
from scipy.optimize import curve_fit
import math

np.random.seed(0)

#Utility Functions
def ggd_pdf(x, sigma, beta):
    #Generalized Gaussian distribution PDF.
    coeff = beta / (2 * sigma * gamma(1 / beta))
    return coeff * np.exp(-np.abs(x / sigma) ** beta)


def fit_ggd(data, bins=100):
    #Fit GGD to data and return (sigma, beta).
    counts, edges = np.histogram(data, bins=bins, density=True)
    centers = (edges[:-1] + edges[1:]) / 2
    p0 = [np.std(data), 2]
    bounds = ([1e-6, 0.1], [np.inf, 10])
    params, _ = curve_fit(ggd_pdf, centers, counts, p0=p0, bounds=bounds)
    return params


def compute_lag_params(series, max_power=8):
    #Compute GGD parameters for lags of 2^i.
    arr = np.asarray(series)
    lags = [2**i for i in range(max_power)]
    factors = [1 / ((i+1)) for i in range(max_power)]
    sigmas, betas = [], []
    for lag in lags:
        if lag >= len(arr): break
        diffs = arr[lag:] - arr[:-lag]
        sigma, beta = fit_ggd(diffs)
        sigmas.append(sigma)
        betas.append(beta)
    return lags[:len(sigmas)], factors[:len(sigmas)], sigmas, betas


def prepare_spectral_constants(N, dt, mask_min=-30, slope=-0.85):
    #Compute FFT factors, positive-frequency mask, and expected log-power.
    k = np.arange(N)
    exp_fac = np.exp(-2j * np.pi * k / N)[: N // 2]
    freqs = fftfreq(N, d=dt)[: N // 2]
    mask = (freqs > 0) & (np.log(freqs + 1e-12) > mask_min)
    expected = slope * np.log(freqs[mask])
    return exp_fac, mask, expected


def spectral_coherence_score(orig_window, cand_window, mask):
    #Compute normalized phase-alignment score between two windows.
    S_o = fft(orig_window * np.hanning(len(orig_window)))[: len(mask)]
    S_u = fft(cand_window * np.hanning(len(cand_window)))[: len(mask)]
    S_o_m = S_o[mask]
    S_u_m = S_u[mask]
    coh = np.real(np.vdot(S_o_m, S_u_m))
    # simple normalization
    return (coh - coh.min()) / (coh.max() - coh.min() + 1e-12)

# --- Core Generation Functions ---
def generate_next_point(series, sample_space, exp_fac, mask, expected,
                        sigmas, betas, lags, factors,
                        N=1000, alpha=0.5):
    #Generate the next point with spectral, intermittency, and phase coherence priors.
    candidates = series[-1] + sample_space
    window = np.array(series[-N:])
    prev_fft = fft(window * np.hanning(N))[: N // 2]
    old_val = window[0]

    # Spectral prior (power fit)
    orig_log = np.log(np.abs(prev_fft)**2 + 1e-12)[mask]
    deltas = candidates - old_val
    updates = prev_fft[None, :] + deltas[:, None] * exp_fac
    logs = np.log(np.abs(updates)**2 + 1e-12)[:, mask]
    delta_err = np.sum((logs - expected)**2, axis=1)
    score_spec = 1 - (delta_err - delta_err.min())/(delta_err.max()-delta_err.min()+1e-12)

    # Phase coherence prior
    # build coherence scores per candidate
    #phase_scores = np.array([
    #    spectral_coherence_score(window, np.concatenate((window[1:], [c])), mask)
    #    for c in candidates
    #])

    # Intermittency prior (GGD)
    prior = np.ones_like(score_spec)
    for lag, factor, sigma, beta in zip(lags, factors, sigmas, betas):
        prior *= ggd_pdf(candidates - series[-lag], sigma, beta)**factor

    # Combine priors
    combined = alpha * score_spec #+ (1-alpha) * phase_scores
    posterior = (combined) * np.sqrt(prior)
    posterior /= np.sum(posterior)
    return np.random.choice(candidates, p=posterior)


def generate_series(series, sample_space, exp_fac, mask, expected,
                    sigmas, betas, lags, factors,
                    iterations=100, N=1000, alpha=1.0):
    #Extend series by iteratively sampling next points.
    for _ in range(iterations):
        series.append(
            generate_next_point(series, sample_space, exp_fac, mask, expected,
                                sigmas, betas, lags, factors, N, alpha)
        )

# --- Plotting Functions ---
def plot_series(series, orig_len=None):
    #Plot original vs generated series.
    plt.figure()
    if orig_len and orig_len < len(series):
        plt.plot(range(orig_len), series[:orig_len], label='Original', alpha=0.7)
        plt.plot(range(orig_len-1, len(series)), series[orig_len-1:], color='C3', label='Generated')
    else:
        plt.plot(series, color='C0')
    plt.title("Timeseries Evolution of Solar Wind Magnitic Field")
    plt.xlabel("Time / min")
    plt.ylabel("Magnetic Field Strength / nT")
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_spectrum(series, N=1000, dt=60, slope=-0.85):
    #Plot log–log Fourier spectrum with trend fit.
    freqs = fftfreq(N, d=dt)[: N // 2]
    m = freqs > 0
    freqs = freqs[m]
    amps = 2/N * np.abs(fft(series[-N:])[: N // 2])[m]
    logf, loga = np.log(freqs), np.log(amps)
    intercept = np.mean(loga - slope*logf)
    plt.figure()
    plt.plot(logf, loga*2, lw=1.5, label='Spectrum')
    plt.plot(logf, 2*slope*logf+2*intercept, '--', label=f'Fit (slope={(slope*6):.2f}/3)')
    plt.title("Spectrum of Solar Wind Turbulance Timeseries")
    plt.xlabel('log(Frequency)')
    plt.ylabel('log(Power)')
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_ggd_lags(series, lags, bins=50, points=500):
    #Plot fitted GGD PDFs for various lags.
    arr = np.asarray(series)
    plt.figure()
    for lag in lags:
        diffs = arr[lag:] - arr[:-lag]
        sigma, beta = fit_ggd(diffs, bins=bins)
        x = np.linspace(np.min(diffs), np.max(diffs), points)
        y = ggd_pdf(x, sigma, beta)
        plt.plot(x, y, lw=1.3, label=f'lag={lag}')
    plt.title("GGD PDFs at Various Lags")
    plt.xlabel("Difference")
    plt.ylabel("Density")
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_histogram_ggd(series, lags, sigmas, betas, bins=50, points=200):
    #Subplots: histogram vs GGD fit per lag.
    arr = np.asarray(series)
    lags = [lag for lag in lags if lag < len(arr)/20]
    n = len(lags)
    cols = 4
    rows = math.ceil(n / cols)
    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*3))
    axes = axes.flatten()
    max_diff = max(np.max(np.abs(arr[lag:] - arr[:-lag])) for lag in lags)
    x = np.linspace(-max_diff, max_diff, points)

    for idx, lag in enumerate(lags):
        diffs = arr[lag:] - arr[:-lag]
        ax = axes[idx]
        ax.hist(diffs, bins=round(len(diffs)/20), density=True, alpha=0.4)
        sigma, beta = sigmas[idx], betas[idx]
        ax.plot(x, ggd_pdf(x, sigma, beta), 'r-', lw=2)
        ax.set_title(f'Lag = {lag}')

    for ax in axes[n:]:
        fig.delaxes(ax)
    plt.tight_layout()
    plt.show()

# --- Main Execution ---
data = np.load('clean_Bx_days.npz')['bx']
series = data[10]
series = series[(series > -20) & (series < 20)].tolist()

increments = np.diff(series)
sample_space = np.linspace(np.min(increments), np.max(increments), 2000)

lags, factors, sigmas, betas = compute_lag_params(series)
exp_fac, mask, expected = prepare_spectral_constants(N=1000, dt=60)
orig_len = len(series)
plot_series(series)
# Generate with phase coherence integrated
generate_series(
    series, sample_space, exp_fac, mask, expected,
    sigmas, betas, lags, factors,
    iterations=1000, N=1000, alpha=0.5
)

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy.special import gamma
from scipy.optimize import curve_fit
from matplotlib.lines import Line2D
import math

# --- Utility Functions (assumed available or import from module) ---
def ggd_pdf(x, sigma, beta):
    coeff = beta / (2 * sigma * gamma(1 / beta))
    return coeff * np.exp(-np.abs(x / sigma) ** beta)

def fit_ggd(data, bins=100):
    counts, edges = np.histogram(data, bins=bins, density=True)
    centers = (edges[:-1] + edges[1:]) / 2
    p0 = [np.std(data), 2]
    bounds = ([1e-6, 0.1], [np.inf, 10])
    params, _ = curve_fit(ggd_pdf, centers, counts, p0=p0, bounds=bounds)
    return params

# --- Enhanced Multi-panel Plot Function with manual styling and bottom-right key ---
def plot_panel(series, orig_len, lags, sigmas, betas, N=1000, dt=60, slope=-0.85):
    fig = plt.figure(constrained_layout=True, figsize=(14, 10))
    fig.patch.set_facecolor('white')
    gs = fig.add_gridspec(2, 2)

    # Helper to style axes
    def style_axis(ax):
        ax.grid(True, which='both', linestyle='--', linewidth=0.6, alpha=0.6)
        ax.set_facecolor('#f9f9f9')
        for spine in ax.spines.values():
            spine.set_visible(True)
            spine.set_color('#cccccc')

    # Top-left: Time Series Evolution
    ax_ts = fig.add_subplot(gs[0, 0])
    if orig_len and orig_len < len(series):
        ax_ts.plot(range(orig_len), series[:orig_len], label='Original', alpha=0.7)
        ax_ts.plot(range(orig_len - 1, len(series)), series[orig_len - 1:], color='C3', label='Generated')
    else:
        ax_ts.plot(series, color='C0')
    ax_ts.set_title('Time Series Evolution', fontsize=12)
    ax_ts.set_xlabel('Time (min)', fontsize=10)
    ax_ts.set_ylabel('Field Strength (nT)', fontsize=10)
    ax_ts.legend(loc='upper right', fontsize='small', frameon=True, facecolor='white', edgecolor='#cccccc')
    style_axis(ax_ts)

    # Top-right: Spectrum (log-log) with target overlay
    ax_spec = fig.add_subplot(gs[0, 1])
    freqs = fftfreq(N, d=dt)[:N // 2]
    mask = freqs > 0
    freqs_m = freqs[mask]
    amps = 2/N * np.abs(fft(series[-N:])[:N // 2])[mask]
    logf = np.log(freqs_m)
    loga = np.log(amps)
    intercept = np.mean(loga - slope * logf)
    ax_spec.plot(logf, loga*2, lw=1.5, label='Spectrum')
    ax_spec.plot(logf, slope*2 * logf + 2*intercept, '--', lw=1.5, label=f'Target Spectrum (slope={slope*2-0.01:.2f})')
    # Overlay expected trend
    # expected should be log-power from prepare_spectral_constants

    ax_spec.set_title("Generated Signal's Power Spectral Density", fontsize=12)
    ax_spec.set_xlabel('ln(Frequency / Hz)', fontsize=10)
    ax_spec.set_ylabel('ln(Amplitude / nT)', fontsize=10)
    ax_spec.legend(loc='upper right', fontsize='small', frameon=True, facecolor='white', edgecolor='#cccccc')
    style_axis(ax_spec)

    # Bottom-left: GGD PDFs at Various Lags
    ax_pdf = fig.add_subplot(gs[1, 0])
    arr = np.asarray(series[-N:])
    for lag in lags:
        if lag >= len(arr): continue
        diffs = arr[lag:] - arr[:-lag]
        sigma, beta = fit_ggd(diffs)
        x = np.linspace(np.min(diffs), np.max(diffs), 500)
        y = ggd_pdf(x, sigma, beta)
        ax_pdf.plot(x, y, lw=1.5, label=f'lag={lag}')
    ax_pdf.set_title('Generalised Gaussian PDFs at Various Lags', fontsize=12)
    ax_pdf.set_xlabel('ΔB over time Lag', fontsize=10)
    ax_pdf.set_ylabel('Probability Density', fontsize=10)
    ax_pdf.legend(fontsize='small', ncol=2, frameon=True, facecolor='white', edgecolor='#cccccc')
    style_axis(ax_pdf)

    # Bottom-right: Histograms + GGD Fits for First 4 Lags with key
    sub_gs = gs[1, 1].subgridspec(2, 2)
    for i, lag in enumerate(lags[:4]):
        ax = fig.add_subplot(sub_gs[i])
        # Plot histogram and fit with labels for legend key
        diffs = np.asarray(series)[lag:] - np.asarray(series)[:-lag]
        ax.hist(diffs, bins=round(len(diffs)/20), density=True, alpha=0.4, label='Histogram')
        sigma, beta = sigmas[i], betas[i]
        x = np.linspace(np.min(diffs), np.max(diffs), 200)
        ax.plot(x, ggd_pdf(x, sigma, beta), 'r-', lw=2, label='GGD Fit')
        ax.set_title(f'Lag = {lag}', fontsize=10)
        ax.tick_params(labelsize='x-small')
        style_axis(ax)
    # Add a unified legend (key) for histograms vs GGD fits in bottom-right
    handles = [Line2D([], [], color='grey', marker='s', linestyle='None', markersize=6, label='Histogram'),
               Line2D([], [], color='r', lw=2, label='GGD Fit')]
    fig.legend(handles=handles, loc='lower right', fontsize='small', frameon=True, facecolor='white', edgecolor='#cccccc')

    fig.suptitle('Synthetic Turbulence Generation, Bx Component', fontsize=16)
    plt.show()

# Example usage:
plot_panel(series, orig_len, lags, sigmas, betas)



import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy.special import gamma
from scipy.optimize import curve_fit
import math

np.random.seed(0)




def prepare_spectral_constants(N, dt, mask_min=-30, slope=-0.85):
    """Compute FFT factors, positive-frequency mask, and expected log-power."""
    k = np.arange(N)
    exp_fac = np.exp(-2j * np.pi * k / N)[: N // 2]
    freqs = fftfreq(N, d=dt)[: N // 2]
    mask = (freqs > 0) & (np.log(freqs + 1e-12) > mask_min)
    expected = slope * np.log(freqs[mask])
    return exp_fac, mask, expected



# --- Core Generation Functions ---
def generate_next_point(series, sample_space, exp_fac, mask, expected,
                        sigmas, betas, lags, factors,
                        N=1000, alpha=0.5):
    """Generate the next point with spectral, intermittency, and phase coherence priors."""
    candidates = series[-1] + sample_space
    window = np.array(series[-N:])
    prev_fft = fft(window * np.hanning(N))[: N // 2]
    old_val = window[0]

    # Spectral prior (power fit)
    orig_log = np.log(np.abs(prev_fft)**2 + 1e-12)[mask]
    deltas = candidates - old_val
    updates = prev_fft[None, :] + deltas[:, None] * exp_fac
    logs = np.log(np.abs(updates)**2 + 1e-12)[:, mask]
    delta_err = np.sum((logs - expected)**2, axis=1)
    score_spec = 1 - (delta_err - delta_err.min())/(delta_err.max()-delta_err.min()+1e-12)

    posterior = score_spec
    posterior /= np.sum(posterior)
    return np.random.choice(candidates, p=posterior)


def generate_series(series, sample_space, exp_fac, mask, expected,
                    sigmas, betas, lags, factors,
                    iterations=100, N=1000, alpha=1.0):
    """Extend series by iteratively sampling next points."""
    for _ in range(iterations):
        series.append(
            generate_next_point(series, sample_space, exp_fac, mask, expected,
                                sigmas, betas, lags, factors, N, alpha)
        )

# --- Plotting Functions ---
def plot_series(series, orig_len=None):
    """Plot original vs generated series."""
    plt.figure()
    if orig_len and orig_len < len(series):
        plt.plot(range(orig_len), series[:orig_len], label='Original', alpha=0.7)
        plt.plot(range(orig_len-1, len(series)), series[orig_len-1:], color='C3', label='Generated')
    else:
        plt.plot(series, color='C0')
    plt.title("Timeseries Evolution of Solar Wind Magnitic Field")
    plt.xlabel("Time / min")
    plt.ylabel("Magnetic Field Strength / nT")
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_spectrum(series, N=1000, dt=60, slope=-0.85):
    """Plot log–log Fourier spectrum with trend fit."""
    freqs = fftfreq(N, d=dt)[: N // 2]
    m = freqs > 0
    freqs = freqs[m]
    amps = 2/N * np.abs(fft(series[-N:])[: N // 2])[m]
    logf, loga = np.log(freqs), np.log(amps)
    intercept = np.mean(loga - slope*logf)
    plt.figure()
    plt.plot(logf, loga*2, lw=1.5, label='Spectrum')
    plt.plot(logf, 2*slope*logf+2*intercept, '--', label=f'Fit (slope={(slope*6):.2f}/3)')
    plt.title("Spectrum of Solar Wind Turbulance Timeseries")
    plt.xlabel('log(Frequency)')
    plt.ylabel('log(Power)')
    plt.legend()
    plt.tight_layout()
    plt.show()




# --- Main Execution ---
data = np.load('clean_Bx_days.npz')['bx']
series = data[10]
series = series[(series > -20) & (series < 20)].tolist()

increments = np.diff(series)
sample_space = np.linspace(np.min(increments), np.max(increments), 2000)

lags, factors, sigmas, betas = compute_lag_params(series)
exp_fac, mask, expected = prepare_spectral_constants(N=1000, dt=60)
orig_len = len(series)
plot_series(series)
# Generate with phase coherence integrated
generate_series(
    series, sample_space, exp_fac, mask, expected,
    sigmas, betas, lags, factors,
    iterations=1000, N=1000, alpha=0.5
)

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
import math

np.random.seed(0)


# -----------------------------
# Utilities: OLS on log–log grid
# -----------------------------
def ols_weights(x):
    """
    Given the design x_k = log f_k (1D array), return exact OLS weights (a_k, b_k)
    such that: alpha = sum_k a_k y_k,  beta = sum_k b_k y_k.
    """
    x = np.asarray(x)
    N = x.size
    Sx = x.sum()
    Sxx = (x * x).sum()
    D = N * Sxx - Sx**2
    if D == 0:
        raise ValueError("Design is singular (all x identical).")
    a = (N * x - Sx) / D
    b = (Sxx - Sx * x) / D
    return a, b, D


def make_mask(freqs, logf_min=None, logf_max=None):
    """
    Positive-frequency mask, optionally restricted to a log-frequency band.
    freqs includes positive and zero; we drop DC outside.
    """
    m = freqs > 0
    if logf_min is not None:
        m &= (np.log(freqs + 1e-12) >= logf_min)
    if logf_max is not None:
        m &= (np.log(freqs + 1e-12) <= logf_max)
    return m


# -------------------------------------------
# Spectral primitives (exact, code-faithful)
# -------------------------------------------
def log_periodogram_lenL(z_window, L, dt, eps=1e-12, mask=None):
    """
    y_k^{(L)} = log( c_L * |X_L[k]|^2 + eps ), DC dropped by the mask.
    Here X_L is the unnormalized DFT of length L on the current window.
    """
    z = np.asarray(z_window)
    assert z.shape[0] == L
    # Unnormalized DFT length L
    X = fft(z, n=L)[: L // 2 + (L % 2)]
    freqs = fftfreq(L, d=dt)[: L // 2 + (L % 2)]
    # Build default mask: drop DC, keep positive freqs
    if mask is None:
        mask = (freqs > 0)
    cL = (2.0 * dt / L) ** 2
    Y = np.log(cL * (np.abs(X) ** 2) + eps)
    return Y[mask], freqs[mask]

def extending_window_ordinals(z_window, p, dt, eps=1e-12, mask=None):
    """
    Exact y_k^{(T)} and y_k^{(T+1)}(p) with independent grids, no sliding update.
    X_{T+1}[k] = S_k + gamma_k * p, where
      S_k = FFT_{T+1}([z_window, 0])[k],  gamma_k = exp(-2π i k T / (T+1)).
    """
    T = len(z_window)
    L2 = T + 1

    # Frequency grids for each length
    freqs_T_full  = fftfreq(T,  d=dt)[: T // 2 + (T % 2)]
    freqs_T1_full = fftfreq(L2, d=dt)[: L2 // 2 + (L2 % 2)]

    # Build masks (positive freqs; optional log-band)
    if mask is None:
        mask_T  = (freqs_T_full  > 0)
        mask_T1 = (freqs_T1_full > 0)
    else:
        logf_min = mask.get("logf_min")
        logf_max = mask.get("logf_max")
        mask_T  = make_mask(freqs_T_full,  logf_min, logf_max)
        mask_T1 = make_mask(freqs_T1_full, logf_min, logf_max)

    # ----- Length T (context) -----
    X_T = fft(z_window, n=T)[: T // 2 + (T % 2)]
    cT  = (2.0 * dt / T) ** 2
    Y_T = np.log(cT * (np.abs(X_T) ** 2) + eps)[mask_T]
    f_T = freqs_T_full[mask_T]

    # ----- Length T+1 (extended) -----
    # S_k from FFT_{T+1} of padded vector [z_window, 0]
    z_pad = np.zeros(L2, dtype=float)
    z_pad[:T] = z_window
    X_pad = fft(z_pad, n=L2)[: L2 // 2 + (L2 % 2)]

    k_idx = np.where(mask_T1)[0]
    gamma = np.exp(-2j * np.pi * (k_idx * T) / L2)  # gamma_k = omega_{T+1}^{kT}
    S_k   = X_pad[mask_T1]
    cT1   = (2.0 * dt / L2) ** 2
    Y_T1  = np.log(cT1 * (np.abs(S_k + gamma * p) ** 2) + eps)
    f_T1  = freqs_T1_full[mask_T1]

    return (Y_T, f_T, mask_T), (Y_T1, f_T1, mask_T1)




# ------------------------------------------------
# Parameter shifts Δα(p), Δβ(p) and spectral loss
# ------------------------------------------------
def delta_params_extending(z_window, p, dt, eps=1e-12, logf_min=None, logf_max=None):
    """
    Exact Δα(p), Δβ(p) from two independent OLS fits on length T and length T+1 grids.
    """
    mask = {"logf_min": logf_min, "logf_max": logf_max}
    (Y_T, f_T, _), (Y_T1, f_T1, _) = extending_window_ordinals(z_window, p, dt, eps, mask)

    # Designs
    x_T = np.log(f_T)
    x_T1 = np.log(f_T1)

    # OLS weights
    a_T, b_T, _ = ols_weights(x_T)
    a_T1, b_T1, _ = ols_weights(x_T1)

    # Parameters
    alpha_T = np.dot(a_T, Y_T)
    beta_T = np.dot(b_T, Y_T)
    alpha_T1 = np.dot(a_T1, Y_T1)
    beta_T1 = np.dot(b_T1, Y_T1)

    return (alpha_T1 - alpha_T), (beta_T1 - beta_T)


def spectral_loss_extending(z_window, p, dt, eps=1e-12, logf_min=None, logf_max=None, lambda_beta=1.0):
    da, db = delta_params_extending(z_window, p, dt, eps, logf_min, logf_max)
    return math.sqrt(da * da + lambda_beta * db * db), da, db


# ---------------------------------------------
# Candidate selection using extending-window loss
# ---------------------------------------------
def choose_next_point(series, sample_space, N, dt, eps=1e-12, logf_min=None, logf_max=None, lambda_beta=1.0, temperature=0.0):
    """
    Given a history 'series', evaluate spectral loss for candidates p = last + inc.
    Picks argmin if temperature==0; otherwise softmin sampling.
    """
    z_window = np.array(series[-N:], dtype=float)
    last = z_window[-1]
    candidates = last + np.asarray(sample_space)

    losses = []
    for p in candidates:
        L, _, _ = spectral_loss_extending(z_window, p, dt, eps, logf_min, logf_max, lambda_beta)
        losses.append(L)
    losses = np.asarray(losses)

    if temperature <= 0:
        p_best = candidates[np.argmin(losses)]
        return float(p_best), losses
    # Softmin sampling
    w = np.exp(-(losses - losses.min()) / max(1e-12, temperature))
    w /= w.sum()
    return float(np.random.choice(candidates, p=w)), losses


def generate_series(series, sample_space, iterations=100, N=1024, dt=60.0, eps=1e-12,
                    logf_min=None, logf_max=None, lambda_beta=1.0, temperature=0.0):
    """
    Extend 'series' iteratively by minimizing the extending-window spectral loss.
    """
    series = list(series)
    for _ in range(iterations):
        p_next, _ = choose_next_point(series, sample_space, N=N, dt=dt, eps=eps,
                                      logf_min=logf_min, logf_max=logf_max,
                                      lambda_beta=lambda_beta, temperature=temperature)
        p_next = np.clip(p_next,-20,20)
        series.append(p_next)
    return series


# ----------------
# Plotting helpers
# ----------------
def plot_series(series, orig_len=None, title="Time series"):
    plt.figure()
    if orig_len and orig_len < len(series):
        plt.plot(range(orig_len), series[:orig_len], label='Original', alpha=0.7)
        plt.plot(range(orig_len - 1, len(series)), series[orig_len - 1:], color='C3', label='Generated')
    else:
        plt.plot(series, color='C0')
    plt.title(title)
    plt.xlabel("Time / mins")
    plt.ylabel("Bx Component / nT")
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_spectrum(series, N=1024, dt=60.0, logf_min=None, logf_max=None, title="Log–log spectrum"):
    z = np.asarray(series[-N:], dtype=float)
    L = N
    X = fft(z, n=L)[: L // 2 + (L % 2)]
    freqs = fftfreq(L, d=dt)[: L // 2 + (L % 2)]
    mask = make_mask(freqs, logf_min, logf_max)
    freqs = freqs[mask]
    cL = (2.0 * dt / L) ** 2
    P = cL * (np.abs(X[mask]) ** 2)
    x = np.log(freqs + 1e-12)
    y = np.log(P + 1e-12)
    a, b, _ = ols_weights(x)
    alpha = float(np.dot(a, y))
    beta = float(np.dot(b, y))
    plt.figure()
    plt.plot(x, y, lw=1.2, label='PSD')
    plt.plot(x, beta + alpha * x, '--', label=f'Target Slope: {alpha:.3f}')
    plt.title(title)
    plt.xlabel('Log Frequency / Hz')
    plt.ylabel('Log Power Density')
    plt.legend()
    plt.tight_layout()
    plt.show()
    return alpha, beta



data = np.load('clean_Bx_days.npz')['bx']
series = data[10][:200]
series = series[(series > -20) & (series < 20)].tolist()
#Candidate increments (simple)
increments = np.diff(series)
sample_space = np.linspace(np.min(increments), np.max(increments), 2000)
# Generation
N = 100
dt = 60.0
series_gen = generate_series(series, sample_space,
                             iterations=200, N=N, dt=dt,
                             logf_min=None, logf_max=None,
                             lambda_beta=0.5, temperature=0.0)
plot_series(series_gen, orig_len=len(series))
plot_spectrum(series_gen, N=N, dt=dt, title="Power Spectral Density for SDA Generation")

def plot_loss_landscape(series, sample_space, N, dt, eps=1e-12,
                        logf_min=None, logf_max=None, lambda_beta=1.0,
                        show_components=False, title="Loss landscape for next point"):
    """
    Plot the extending-window spectral loss for candidate next values.

    Parameters
    ----------
    series : sequence of float
        Full time series; the last N points form the context window.
    sample_space : 1D array
        Candidate *increments* Δ (as in your code). Candidates are p = last + Δ.
        If you already have absolute candidate p values, pass them and set `as_absolute=True` below.
    N : int
        Context window length.
    dt : float
        Sampling interval.
    eps, logf_min, logf_max, lambda_beta : see spectral_loss_extending
    show_components : bool
        If True, also plot Δα and Δβ contributions.
    title : str
        Plot title.

    Returns
    -------
    p_best : float
        Candidate value with minimal loss.
    grid_p : (M,) ndarray
        Candidate values evaluated.
    losses : (M,) ndarray
        Spectral loss values for each candidate.
    d_alpha : (M,) ndarray
        Δα(p) for each candidate (returned even if not plotted).
    d_beta : (M,) ndarray
        Δβ(p) for each candidate (returned even if not plotted).
    """
    z_window = np.array(series[-N:], dtype=float)
    last = z_window[-1]
    grid_p = last + np.asarray(sample_space)

    losses = np.empty_like(grid_p, dtype=float)
    d_alpha = np.empty_like(grid_p, dtype=float)
    d_beta  = np.empty_like(grid_p, dtype=float)

    for i, p in enumerate(grid_p):
        L, da, db = spectral_loss_extending(z_window, p, dt, eps,
                                            logf_min=logf_min, logf_max=logf_max,
                                            lambda_beta=lambda_beta)
        losses[i] = L
        d_alpha[i] = da
        d_beta[i]  = db

    i_min = int(np.argmin(losses))
    p_best = float(grid_p[i_min])

    # ---- plotting ----
    plt.figure(figsize=(7, 4.2))
    plt.plot(grid_p, losses, lw=1.8, label=r'$\mathcal{L}_{\mathrm{spec}}(p)$')
    plt.xlabel("Proposed Next Value / nT")
    plt.ylabel("Spectral Loss")
    plt.axvline(last, ls='--', alpha=0.5, label='Previous Value')
    plt.title(title)
    plt.legend()
    plt.tight_layout()
    plt.show()


    return p_best, grid_p, losses, d_alpha, d_beta
# build a reasonable candidate grid around the last value
last = series[-1]
# e.g. scan ±5 standard deviations of recent increments
inc = np.diff(series[-N:])
grid_inc = np.linspace(np.percentile(inc, 0), np.percentile(inc, 100), 301)

p_best, grid_p, losses, d_alpha, d_beta = plot_loss_landscape(
    series, grid_inc, N=N, dt=dt,
    logf_min=None, logf_max=None,      # or restrict to your inertial band
    lambda_beta=0.5,                   # or whatever you use in training
    show_components=True,
    title="Spectral loss vs next value"
)